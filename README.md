# üöÄ E-commerce Realtime Data Pipeline

> **Full-stack realtime analytics platform**: Event-driven architecture v·ªõi Kafka, Spark Streaming, v√† React Dashboard

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue)](https://www.docker.com/)
[![React](https://img.shields.io/badge/React-18.3-blue)](https://reactjs.org/)
[![Apache Kafka](https://img.shields.io/badge/Kafka-7.5-red)](https://kafka.apache.org/)
[![Apache Spark](https://img.shields.io/badge/Spark-3.5-orange)](https://spark.apache.org/)

---

## üìñ Gi·ªõi Thi·ªáu

H·ªá th·ªëng x·ª≠ l√Ω v√† ph√¢n t√≠ch d·ªØ li·ªáu **realtime** cho n·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠. X·ª≠ l√Ω h√†ng tri·ªáu events/gi√¢y v·ªõi ƒë·ªô tr·ªÖ d∆∞·ªõi 1 gi√¢y, t√≠nh to√°n KPI theo th·ªùi gian th·ª±c v√† hi·ªÉn th·ªã tr√™n dashboard t∆∞∆°ng t√°c.

### ‚ú® Features

- üìä **Realtime Analytics Dashboard** - Hi·ªÉn th·ªã GMV, order rate, success rate c·∫≠p nh·∫≠t li√™n t·ª•c
- ‚ö° **Stream Processing** - X·ª≠ l√Ω events v·ªõi ƒë·ªô tr·ªÖ < 1s b·∫±ng Spark Structured Streaming
- üé® **Event Generator UI** - Control panel ƒë·ªÉ t·∫°o events v·ªõi custom parameters
- üîÑ **Auto-scaling Pipeline** - T·ª± ƒë·ªông scale theo volume d·ªØ li·ªáu
- üìà **Multi-timeframe KPI** - Analytics theo 1 ph√∫t, 15 ph√∫t, 1 gi·ªù, 24 gi·ªù
- üê≥ **Full Docker** - Deploy to√†n b·ªô h·ªá th·ªëng v·ªõi 1 l·ªánh

### üéØ Use Cases

- ‚úÖ **UC03**: Parse & Validate Events
- ‚úÖ **UC04**: Clean & Deduplicate  
- ‚úÖ **UC05**: Calculate KPIs (windowing aggregation)
- ‚úÖ **UC06**: Persist to PostgreSQL

---

## üèóÔ∏è Ki·∫øn Tr√∫c H·ªá Th·ªëng

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    HTTP GET     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Event Generator ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Producer Poller  ‚îÇ
‚îÇ   (Node.js)     ‚îÇ                 ‚îÇ    (Python)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇ Produce
                                             ‚ñº
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ   Kafka Broker   ‚îÇ
                                    ‚îÇ  (events_raw)    ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇ Stream
                                             ‚ñº
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ Spark Streaming  ‚îÇ
                                    ‚îÇ UC03-UC06 Jobs   ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇ Write
                                             ‚ñº
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ   PostgreSQL     ‚îÇ
                                    ‚îÇ events_clean +   ‚îÇ
                                    ‚îÇ kpi_1m tables    ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇ Query
                                             ‚ñº
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ React Dashboard  ‚îÇ
                                    ‚îÇ   (Port 5173)    ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pipeline Flow:**
1. **Event Generator** ‚Üí REST API t·∫°o events v·ªõi distribution 30-25-35-8-2%
2. **Producer Poller** ‚Üí Poll API m·ªói 500ms v√† push v√†o Kafka
3. **Kafka Broker** ‚Üí Message queue (topic: `events_raw`)
4. **Spark Streaming** ‚Üí Real-time processing (validate, clean, aggregate)
5. **PostgreSQL** ‚Üí Persist events v√† KPI tables
6. **React Dashboards** ‚Üí Visualize realtime analytics

---

## üõ†Ô∏è Tech Stack

### Backend
- **Apache Kafka 7.5** - Distributed streaming platform
- **Apache Spark 3.5** - Stream processing v·ªõi Structured Streaming
- **PostgreSQL 15** - Relational database
- **Python 3.11** - Spark jobs & Producer
- **Node.js 20** - Event Generator REST API

### Frontend  
- **React 18.3** - UI framework
- **TypeScript 5.3** - Type safety
- **Vite 5.4** - Build tool & dev server
- **TailwindCSS 3.4** - Utility-first CSS

### DevOps
- **Docker & Docker Compose** - Containerization (8 services)
- **Nginx** - Production web server cho frontends

---

## üöÄ Quick Start

**Y√™u c·∫ßu:** Docker Desktop 20.10+

```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git
cd YOUR_REPO

# Start t·∫•t c·∫£ (1 l·ªánh)
docker-start.bat

# Ch·ªù 60s, sau ƒë√≥ truy c·∫≠p:
# - Generator UI: http://localhost:5174
# - Dashboard:    http://localhost:5173
# - API:          http://localhost:7070
```

**üìö H∆∞·ªõng d·∫´n chi ti·∫øt:** [docs/QUICKSTART.md](docs/QUICKSTART.md)

---

## üìÅ C·∫•u Tr√∫c Project

```
ecommerce-realtime-pipeline/
‚îÇ
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ generator-api/          # Node.js REST API (port 7070)
‚îÇ   ‚îú‚îÄ‚îÄ producer-poller/        # Python Kafka Producer
‚îÇ   ‚îî‚îÄ‚îÄ spark-streaming/        # Spark Streaming Jobs
‚îÇ
‚îú‚îÄ‚îÄ frontend/                   # Analytics Dashboard (port 5173)
‚îú‚îÄ‚îÄ generator-ui/               # Generator Control UI (port 5174)
‚îÇ
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml      # üê≥ 8 services
‚îÇ   ‚îî‚îÄ‚îÄ postgres/init.sql       # Database schema
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ QUICKSTART.md           # Setup trong 5 ph√∫t
‚îÇ   ‚îú‚îÄ‚îÄ DOCKER_SETUP.md         # Docker chi ti·∫øt
‚îÇ   ‚îî‚îÄ‚îÄ ARCHITECTURE.md         # System design
‚îÇ
‚îú‚îÄ‚îÄ docker-start.bat            # üöÄ Start script
‚îú‚îÄ‚îÄ docker-stop.bat             # üõë Stop script
‚îî‚îÄ‚îÄ README.md                   # üëà B·∫†N ƒêANG ƒê·ªåC
```

---

## üìä Services Overview

| Service | Container | Port | Tech | Description |
|---------|-----------|------|------|-------------|
| **Zookeeper** | zookeeper | 2181 | Confluent | Kafka coordination |
| **Kafka** | kafka | 9092 | Confluent | Event streaming broker |
| **PostgreSQL** | postgres | 5432 | Alpine | Database |
| **Generator API** | api-generator | 7070 | Node.js | Event REST API |
| **Producer** | producer-poller | - | Python | API ‚Üí Kafka |
| **Spark** | spark-streaming | - | Python + Java | Stream processing |
| **Generator UI** | generator-ui | 5174 | React + Nginx | Control dashboard |
| **Dashboard** | frontend-dashboard | 5173 | React + Nginx | Analytics UI |

---

## üé¨ Demo

### T·∫°o Events
```bash
# Single event
curl http://localhost:7070/gen/event

# Batch 100 events
curl -X POST http://localhost:7070/gen/emit \
  -H "Content-Type: application/json" \
  -d '{"count": 100}'
```

### Xem Kafka Stream
```bash
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic events_raw \
  --from-beginning
```

### Query Database
```bash
docker exec -it postgres psql -U app -d realtime -c \
  "SELECT event_type, COUNT(*) FROM events_clean GROUP BY event_type;"
```

---

## üìö Documentation

- **[QUICKSTART.md](docs/QUICKSTART.md)** ‚ö° - Setup trong 5 ph√∫t
- **[DOCKER_SETUP.md](docs/DOCKER_SETUP.md)** üê≥ - Docker guide ƒë·∫ßy ƒë·ªß
- **[ARCHITECTURE.md](docs/ARCHITECTURE.md)** üèóÔ∏è - System architecture & design

---

## üêõ Troubleshooting

**Services kh√¥ng start:**
```bash
cd infra
docker-compose ps        # Check status
docker-compose logs -f   # View logs
```

**Reset to√†n b·ªô:**
```bash
cd infra
docker-compose down -v   # Delete all data
docker-compose up -d --build
```

**üëâ Chi ti·∫øt:** [docs/QUICKSTART.md#troubleshooting](docs/QUICKSTART.md#troubleshooting)

---

## üìù Development

### Local Development
```bash
# Stop production containers
cd infra && docker-compose stop generator-ui

# Run dev mode with hot reload
cd generator-ui && npm run dev
```

### Add New Service
1. T·∫°o Dockerfile trong `services/your-service/`
2. Add service v√†o `infra/docker-compose.yml`
3. Rebuild: `docker-compose up -d --build your-service`

---

## ü§ù Contributing

Contributions are welcome! Please:
1. Fork repository
2. Create feature branch: `git checkout -b feature/AmazingFeature`
3. Commit changes: `git commit -m 'Add AmazingFeature'`
4. Push to branch: `git push origin feature/AmazingFeature`
5. Open Pull Request

---

## üìÑ License

MIT License - see [LICENSE](LICENSE) file

---

## üôè Acknowledgments

- Apache Kafka & Spark communities
- React & Vite teams  
- Docker & Confluent

---

## üìß Contact

**Author**: Your Name  
**Email**: your.email@example.com  
**GitHub**: [@yourusername](https://github.com/yourusername)

---

**‚≠ê Star repo n·∫øu project h·ªØu √≠ch!**
