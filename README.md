# ğŸš€ E-commerce Realtime Data Pipeline

> **Full-stack realtime analytics platform**: Kafka â†’ Spark Structured Streaming â†’ PostgreSQL â†’ React Dashboard

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![React](https://img.shields.io/badge/React-18.3-blue)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue)](https://www.typescriptlang.org/)
[![Apache Kafka](https://img.shields.io/badge/Kafka-7.5-red)](https://kafka.apache.org/)
[![Apache Spark](https://img.shields.io/badge/Spark-3.5-orange)](https://spark.apache.org/)

---

## ğŸ“– Giá»›i Thiá»‡u

Há»‡ thá»‘ng xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u **realtime** cho ná»n táº£ng thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­, bao gá»“m:

- ğŸ“Š **Dashboard Realtime**: Hiá»ƒn thá»‹ metrics (GMV, order rate, success rate) cáº­p nháº­t liÃªn tá»¥c
- âš¡ **Stream Processing**: Xá»­ lÃ½ hÃ ng triá»‡u events vá»›i Ä‘á»™ trá»… dÆ°á»›i 1 giÃ¢y
- ğŸ”„ **Auto-scaling**: Pipeline xá»­ lÃ½ tá»± Ä‘á»™ng scale theo volume dá»¯ liá»‡u
- ğŸ“ˆ **Multi-timeframe Analytics**: KPI theo 1 phÃºt, 15 phÃºt, 1 giá», 24 giá»

### Kiáº¿n TrÃºc Tá»•ng Quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP GET     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Event Generator â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Producer Poller  â”‚
â”‚   (Node.js)     â”‚                 â”‚    (Python)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚ Produce
                                             â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   Kafka Broker   â”‚
                                    â”‚  (events_raw)    â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚ Stream
                                             â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Spark Streaming  â”‚
                                    â”‚ UC03-UC06 Jobs   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚ Write
                                             â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   PostgreSQL     â”‚
                                    â”‚ events_clean +   â”‚
                                    â”‚ kpi_1m tables    â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚ Query
                                             â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ React Dashboard  â”‚
                                    â”‚   (Port 5173)    â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ YÃªu Cáº§u MÃ´i TrÆ°á»ng

| Tool | Version | Má»¥c Ä‘Ã­ch |
|------|---------|----------|
| **Docker** | 20.10+ | Cháº¡y Kafka, Zookeeper, PostgreSQL |
| **Docker Compose** | 2.0+ | Orchestration infrastructure |
| **Node.js** | 20+ | Event Generator API |
| **Python** | 3.8+ | Producer Poller + Spark |
| **Java** | 11+ | Spark Runtime (JRE) |
| **npm** | 10+ | Frontend dependencies |

### CÃ i Äáº·t Nhanh

**Windows**:
```powershell
choco install docker-desktop nodejs python jdk11
```

**macOS**:
```bash
brew install docker node python@3.11 openjdk@11
```

**Linux (Ubuntu)**:
```bash
sudo apt update
sudo apt install docker.io docker-compose nodejs npm python3 python3-pip openjdk-11-jre
```

---

## ğŸ“ Cáº¥u TrÃºc Project

```
ecommerce-realtime-pipeline/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api-generator/          # REST API sinh events ngáº«u nhiÃªn
â”‚   â”œâ”€â”€ producer.py             # Poll API â†’ push Kafka
â”‚   â”œâ”€â”€ spark_stream.py         # Spark Streaming: Kafka â†’ Postgres
â”‚   â”œâ”€â”€ generator.py            # (Legacy - khÃ´ng dÃ¹ng)
â”‚   â”œâ”€â”€ schema.sql              # PostgreSQL schema
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”‚
â”œâ”€â”€ src/                        # React Dashboard
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ features/
â”‚   â””â”€â”€ lib/
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ QUICKSTART.md
â”‚   â”œâ”€â”€ DATA_SOURCE_SETUP.md
â”‚   â”œâ”€â”€ BACKEND_SETUP.md
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â””â”€â”€ GITHUB_SETUP.md
â”‚
â”œâ”€â”€ scripts/                    # Helper scripts
â”‚   â”œâ”€â”€ start-pipeline.sh
â”‚   â””â”€â”€ git-init.sh
â”‚
â”œâ”€â”€ docker-compose.yml          # Infrastructure
â”œâ”€â”€ package.json                # Frontend dependencies
â”œâ”€â”€ vite.config.ts              # Vite configuration
â””â”€â”€ README.md                   # ğŸ‘ˆ Báº N ÄANG Äá»ŒC FILE NÃ€Y
```

---

## ğŸš€ Quick Start

**ğŸ‘‰ Xem hÆ°á»›ng dáº«n chi tiáº¿t:** [docs/SETUP.md](docs/SETUP.md)

```powershell
# 1. Start Infrastructure
cd infra && docker-compose up -d

# 2. Start Generator API
cd services/generator-api && npm install && npm start

# 3. Start Producer
cd services/producer-poller && pip install -r requirements.txt && python producer.py

# 4. Start Frontend
cd frontend && npm install && npm run dev
```

**Dashboard:** http://localhost:5173

---

## ğŸ“š Documentation

### Setup & Guides
- **[SETUP.md](docs/SETUP.md)** â­ Setup guide cho ngÆ°á»i má»›i (báº¯t Ä‘áº§u tá»« Ä‘Ã¢y!)
- [BACKEND_SETUP.md](docs/BACKEND_SETUP.md) - Chi tiáº¿t cáº¥u hÃ¬nh backend

### Architecture & Design
- [ARCHITECTURE.md](docs/ARCHITECTURE.md) - Kiáº¿n trÃºc há»‡ thá»‘ng
- [DATA_SOURCE_SETUP.md](docs/DATA_SOURCE_SETUP.md) - Cáº¥u hÃ¬nh data source
- [DEMO_SCRIPT.md](docs/DEMO_SCRIPT.md) - Script demo

### Components
- [Generator API](docs/readmes/GENERATOR_API.md) - REST API documentation
- [Generator UI](docs/readmes/GENERATOR_UI.md) - React dashboard
- [Environment](docs/readmes/ENV.md) - Environment config

---

### ğŸ“‹ Chi Tiáº¿t Tá»«ng BÆ°á»›c

#### **BÆ°á»›c 1: Khá»Ÿi Äá»™ng Infrastructure**

```powershell
docker-compose up -d
```

Chá» 30-60 giÃ¢y Ä‘á»ƒ Kafka khá»Ÿi Ä‘á»™ng hoÃ n toÃ n:

```powershell
# Kiá»ƒm tra status
docker ps

# Kiá»ƒm tra Kafka ready
docker logs kafka | Select-String "started"
```

**Services Ä‘ang cháº¡y**:
- Zookeeper (port 2181)
- Kafka Broker (port 9092)
- PostgreSQL (port 5432)

#### **BÆ°á»›c 2: Cháº¡y API Generator**

```powershell
cd backend/api-generator
npm install
npm start
```

**Test API**:
```powershell
curl http://localhost:7070/gen/event
```

#### **BÆ°á»›c 3: Cháº¡y Producer Poller**

Má»Ÿ terminal má»›i:

```powershell
pip install -r backend/requirements.txt
python backend/producer.py
```

**Log thÃ nh cÃ´ng**:
```
âœ… Connected to Kafka: localhost:9092
ğŸ“¥ Pulled event from API: payment_success | Order: ORD-...
ğŸ“¤ Produced to Kafka: topic=events_raw | partition=1 | offset=42
```

#### **BÆ°á»›c 4: Cháº¡y Spark Streaming**

Má»Ÿ terminal má»›i:

```powershell
python backend/spark_stream.py
```

**Log thÃ nh cÃ´ng**:
```
âœ… Spark Streaming started
âœ… Reading from Kafka: events_raw
ğŸ“Š Processing batch 1 with 100 events
âœ… Written to PostgreSQL
```

#### **BÆ°á»›c 5: Cháº¡y Frontend**

Má»Ÿ terminal má»›i:

```powershell
npm install
npm run dev
```

Má»Ÿ browser: **http://localhost:5173**

---

## ğŸ¬ Demo Nhanh (Cho Báº£o Vá»‡ Äá»“ Ãn)

### Scenario 1: Realtime Pipeline HoÃ n Chá»‰nh

```powershell
# 1. Start táº¥t cáº£ services (3-5 phÃºt)
docker-compose up -d
cd backend/api-generator && npm start &
python backend/producer.py &
python backend/spark_stream.py &
npm run dev

# 2. Má»Ÿ dashboard: http://localhost:5173
# 3. Giáº£i thÃ­ch:
#    - Events tá»« API Generator â†’ Producer â†’ Kafka
#    - Spark Ä‘á»c Kafka â†’ xá»­ lÃ½ â†’ ghi Postgres
#    - Dashboard query Postgres â†’ hiá»ƒn thá»‹ realtime
```

### Scenario 2: Kiá»ƒm Tra Kafka Consumer

```powershell
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic events_raw \
  --from-beginning \
  --max-messages 10
```

### Scenario 3: Kiá»ƒm Tra PostgreSQL

```powershell
docker exec -it postgres psql -U app -d realtime

# Query KPI
SELECT * FROM kpi_1m ORDER BY window_start DESC LIMIT 5;

# Query events
SELECT event_type, COUNT(*) FROM events_clean GROUP BY event_type;
```

### Scenario 4: Stop ToÃ n Bá»™

```powershell
# Stop Python processes (Ctrl+C trong tá»«ng terminal)
# Stop Node.js (Ctrl+C)
# Stop Docker
docker-compose down
```

---

## ğŸ“Š CÃ¡c Use Cases ÄÃ£ Implement

| Use Case | MÃ´ táº£ | Status |
|----------|-------|--------|
| **UC03** | Parse & Validate Events | âœ… HoÃ n thÃ nh |
| **UC04** | Clean & Deduplicate | âœ… HoÃ n thÃ nh |
| **UC05** | Calculate KPIs (1 min window) | âœ… HoÃ n thÃ nh |
| **UC06** | Persist to PostgreSQL | âœ… HoÃ n thÃ nh |

---

## ğŸ”§ Configuration

### Environment Variables

**Producer Poller** (`backend/.env`):
```env
API_URL=http://localhost:7070/gen/event
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC=events_raw
POLL_INTERVAL_MS=500
```

**Spark Streaming**:
```python
# backend/spark_stream.py
KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"
POSTGRES_HOST = "localhost"
POSTGRES_PORT = 5432
POSTGRES_DB = "realtime"
```

**Frontend** (`vite.config.ts`):
```typescript
server: {
  port: 5173,
  proxy: {
    '/api': 'http://localhost:8080'  // Náº¿u cÃ³ API backend
  }
}
```

---

## ğŸ› Troubleshooting

### Kafka Connection Error

**Triá»‡u chá»©ng**: `NoBrokersAvailable`

**Giáº£i phÃ¡p**:
```powershell
docker-compose restart kafka
# Chá» 30s
docker logs kafka | Select-String "started"
```

### PostgreSQL Connection Error

**Triá»‡u chá»©ng**: `Connection refused to localhost:5432`

**Giáº£i phÃ¡p**:
```powershell
docker ps  # Check postgres running
docker logs postgres

# Náº¿u cáº§n init láº¡i schema
docker exec -it postgres psql -U app -d realtime -f /docker-entrypoint-initdb.d/init.sql
```

### Frontend Build Error

**Triá»‡u chá»©ng**: `Module not found`

**Giáº£i phÃ¡p**:
```powershell
rm -rf node_modules package-lock.json
npm install
npm run dev
```

---

## ğŸ“š Documentation Chi Tiáº¿t

- [ğŸ“– QUICKSTART.md](docs/QUICKSTART.md) - HÆ°á»›ng dáº«n cháº¡y nhanh
- [ğŸ”§ DATA_SOURCE_SETUP.md](docs/DATA_SOURCE_SETUP.md) - Thiáº¿t láº­p nguá»“n dá»¯ liá»‡u (API â†’ Kafka)
- [âš™ï¸ BACKEND_SETUP.md](docs/BACKEND_SETUP.md) - Spark Streaming & PostgreSQL
- [ğŸ—ï¸ ARCHITECTURE.md](docs/ARCHITECTURE.md) - Kiáº¿n trÃºc há»‡ thá»‘ng
- [ğŸ™ GITHUB_SETUP.md](docs/GITHUB_SETUP.md) - Push lÃªn GitHub

---

## ğŸ”„ Cháº¿ Äá»™ MOCK vs REAL

### MOCK Mode (Default)

API Generator tá»± táº¡o dá»¯ liá»‡u ngáº«u nhiÃªn - phÃ¹ há»£p demo:

```javascript
// backend/api-generator/server.js
const eventType = weightedRandom(EVENT_TYPES);  // Random events
```

### REAL Mode (TÃ­ch Há»£p API Tháº­t)

Sá»­a `backend/producer.py` Ä‘á»ƒ call API tháº­t thay vÃ¬ API Generator:

```python
# Thay vÃ¬
API_URL = 'http://localhost:7070/gen/event'

# ThÃ nh
API_URL = 'https://your-real-api.com/events'
```

---

## ğŸ“ Tech Stack

### Backend
- **Apache Kafka 7.5.0** - Distributed streaming platform
- **Apache Spark 3.5.0** - Stream processing engine
- **PostgreSQL 15** - Relational database
- **Python 3.11** - Scripting & Spark jobs
- **Node.js 20** - Event Generator API

### Frontend
- **React 18.3** - UI framework
- **TypeScript 5.3** - Type safety
- **Vite 5.4** - Build tool
- **TailwindCSS 3.4** - Styling

### DevOps
- **Docker & Docker Compose** - Containerization
- **Git** - Version control

---

## ğŸ“ TODO / Future Enhancements

- [ ] ThÃªm API backend cho dashboard (hiá»‡n táº¡i query trá»±c tiáº¿p Postgres tá»« frontend)
- [ ] ThÃªm authentication (JWT)
- [ ] ThÃªm monitoring (Prometheus + Grafana)
- [ ] ThÃªm alerting (khi error rate > threshold)
- [ ] Scale Kafka lÃªn 3 brokers
- [ ] ThÃªm unit tests (Jest, pytest)

---

## ğŸ‘¥ Contributors

- **Your Name** - Initial work

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Apache Kafka & Spark communities
- React & Vite teams
- Docker team

---

**â­ Náº¿u project há»¯u Ã­ch, Ä‘á»«ng quÃªn star repo!**

**ğŸ“§ Contact**: your.email@example.com
